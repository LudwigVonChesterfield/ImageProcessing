{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.8 * len(training_data))\n",
    "val_len = len(training_data) - train_len\n",
    "torch.manual_seed(42)\n",
    "train_data, val_data = random_split(training_data, [train_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0][0].shape, training_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=4, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=4, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=4, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes=len(labels_map))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred, probs = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred, probs = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train_acc = []\n",
    "train_losses = []\n",
    "test_acc = []\n",
    "test_losses = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "    train_correct, train_loss = test(train_dataloader, model, loss_fn)\n",
    "    train_acc.append(train_correct)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Train Error: \\n Accuracy: {(100*train_correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    test_correct, test_loss = test(test_dataloader, model, loss_fn)\n",
    "    test_acc.append(test_correct)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*test_correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    # torch.save(model.state_dict(), f\"models/model{t}.pth\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = random.choice(self.dataset)\n",
    "\n",
    "        #We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0, 1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #Look untill the same class image is found\n",
    "                img2, label2 = random.choice(self.dataset) \n",
    "                if label1 == label2:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                #Look untill a different class image is found\n",
    "                img2, label2 = random.choice(self.dataset) \n",
    "                if label1 != label2:\n",
    "                    break\n",
    "        \n",
    "        return img1, img2, torch.from_numpy(np.array([int(label1 != label2)], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(240, 80),\n",
    "            nn.BatchNorm1d(80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 30),\n",
    "            nn.BatchNorm1d(30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        combined_features = torch.cat([input1, input2], dim=1)\n",
    "        # combined_features = input1 * input2\n",
    "\n",
    "        return self.fc(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = SiameseNetwork()\n",
    "siamese = siamese.to(device)\n",
    "\n",
    "siamese_criterion = torch.nn.BCELoss()\n",
    "siamese_optimizer = torch.optim.Adam(siamese.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = SiameseDataset(train_data)\n",
    "val_datas = SiameseDataset(val_data)\n",
    "test_datas = SiameseDataset(test_data)\n",
    "\n",
    "siam_test_dataloader = DataLoader(test_datas, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "feature_model = copy.deepcopy(model)\n",
    "feature_model.classifier = nn.Identity()\n",
    "feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "correct_history = []\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in tqdm(range(20)):\n",
    "\n",
    "    total_loss, correct = 0, 0\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for img0, img1, label in siam_test_dataloader:\n",
    "        img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
    "\n",
    "        img0, probs0 = feature_model(img0)\n",
    "        img1, probs1 = feature_model(img1)\n",
    "\n",
    "        prob = siamese(img0, img1)\n",
    "        loss = siamese_criterion(prob, label)\n",
    "\n",
    "        siamese_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        siamese_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += torch.count_nonzero(label == (prob > 0.9)).item()\n",
    "\n",
    "    print(\"Loss, Correct\", total_loss, correct)\n",
    "        \n",
    "    loss_history.append(total_loss)\n",
    "    correct_history.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = test_data[1][0]\n",
    "img1 = test_data[1][0]\n",
    "\n",
    "img0 = img0.unsqueeze(1)\n",
    "img1 = img1.unsqueeze(1)\n",
    "\n",
    "img0 = img0.to(device)\n",
    "img1 = img1.to(device)\n",
    "\n",
    "img0, probs0 = feature_model(img0)\n",
    "img1, probs1 = feature_model(img1)\n",
    "\n",
    "print(img0.shape, img1.shape)\n",
    "\n",
    "siamese(img0, img1)[0].item(), test_data[1][1], test_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(img0, dataset):\n",
    "    res = []\n",
    "    \n",
    "    img0 = img0.unsqueeze(1)\n",
    "    img0 = img0.to(device)\n",
    "    img0, probs0 = feature_model(img0)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        img1 = dataset[i][0]\n",
    "        img1 = img1.unsqueeze(1)\n",
    "        img1 = img1.to(device)\n",
    "        img1, probs1 = feature_model(img1)\n",
    "        \n",
    "        res.append(siamese(img0, img1)[0].item())\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.arange(0, 1000)\n",
    "test_data_sub = data_utils.Subset(test_data, indices)\n",
    "\n",
    "similar = find_similar(test_data[1][0], test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similar = np.argsort(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_5 = sorted_similar[:5]\n",
    "\n",
    "print(\"Most similar:\", most_similar_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes of most similar:\", [labels_map[test_data_sub[i][1]] for i in most_similar_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_similar_5 = sorted_similar[-5:]\n",
    "\n",
    "print(\"Least similar:\", least_similar_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes of least similar:\", [labels_map[test_data_sub[i][1]] for i in least_similar_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[1][0].squeeze(), cmap=\"gray\")\n",
    "plt.title(labels_map[test_data[1][1]])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15, 6))\n",
    "cols, rows = 5, 2\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    if i < 6:\n",
    "        sample_idx = most_similar_5[i - 1]\n",
    "    else:\n",
    "        sample_idx = least_similar_5[i - 6]\n",
    "        \n",
    "    img, label = test_data_sub[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'{labels_map[label]} {1.0 - similar[sample_idx]:.5f}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_preds(dataloader):\n",
    "    res = []\n",
    "\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        pred, prob = model(X)\n",
    "        pred = pred.detach().cpu()\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            res.append((pred[i].numpy(), y[i].numpy()))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [p[0] for p in all_preds(test_dataloader)]\n",
    "labels = [p[1] for p in all_preds(test_dataloader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='pca', random_state=42, method='barnes_hut', n_iter=500, verbose=2)\n",
    "tsne_features = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_categories = list(labels_map.values())\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
    "    plt.scatter(tsne_features[np.where(np.array(labels) == c_group), 0], tsne_features[np.where(np.array(labels) == c_group), 1], \n",
    "                marker='o', color=c_color, linewidth=1, alpha=0.8, label=c_label)\n",
    "    \n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('t-SNE on Testing Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CV lab3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
